<!doctype html><html lang=en><head><title>Programming as Theory Building, Part II: When Institutions Crumble Â· cekrem.github.io</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Christian Ekrem"><meta name=description content="Software development teams are institutions. AI degrades them in ways we're only beginning to understand."><meta name=keywords content="developer,personal"><meta name=fediverse:creator content><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://cekrem.github.io/images/banner.jpg"><meta name=twitter:title content="Programming as Theory Building, Part II: When Institutions Crumble"><meta name=twitter:description content="Software development teams are institutions. AI degrades them in ways we're only beginning to understand."><meta property="og:url" content="https://cekrem.github.io/posts/programming-as-theory-building-part-ii/"><meta property="og:site_name" content="cekrem.github.io"><meta property="og:title" content="Programming as Theory Building, Part II: When Institutions Crumble"><meta property="og:description" content="Software development teams are institutions. AI degrades them in ways we're only beginning to understand."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-01-19T00:00:00+00:00"><meta property="article:modified_time" content="2026-01-19T00:00:00+00:00"><meta property="article:tag" content="Programming"><meta property="article:tag" content="Software-Engineering"><meta property="article:tag" content="Theory"><meta property="article:tag" content="Llm"><meta property="article:tag" content="Ai"><meta property="article:tag" content="Craft"><meta property="og:image" content="https://cekrem.github.io/images/banner.jpg"><link rel=canonical href=https://cekrem.github.io/posts/programming-as-theory-building-part-ii/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.e8eb08b92eec0f2a19c8cbe4eda1f38c703416996d08f55900541ba798921e5b.css integrity="sha256-6OsIuS7sDyoZyMvk7aHzjHA0FpltCPVZAFQbp5iSHls=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a93347c2833a476d1c25ae74bed3f80024fc1eaf1a33d084c2211065513e5c42.css integrity="sha256-qTNHwoM6R20cJa50vtP4ACT8Hq8aM9CEwiEQZVE+XEI=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/favicon.svg sizes=any><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://cekrem.github.io/>cekrem.github.io
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/how-i-met-jesus/>Jesus!?</a></li><li class=navigation-item><a class=navigation-link href=/about/>About</a></li><li class=navigation-item><a class=navigation-link href=/posts/books-i-think-software-engineers-should-read>Recommended Books</a></li><li class=navigation-item><a class=navigation-link href=https://creators.spotify.com/pod/show/disippel>Podcast (ðŸ‡³ðŸ‡´)</a></li><li class=navigation-item><a class=navigation-link href=/posts/>Blog</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://cekrem.github.io/posts/programming-as-theory-building-part-ii/>Programming as Theory Building, Part II: When Institutions Crumble</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2026-01-19T00:00:00Z>January 19, 2026
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
10-minute read</span></div><div class=tags><i class="fa-solid fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/programming/>Programming</a>
</span><span class=separator>â€¢</span>
<span class=tag><a href=/tags/software-engineering/>Software-Engineering</a>
</span><span class=separator>â€¢</span>
<span class=tag><a href=/tags/theory/>Theory</a>
</span><span class=separator>â€¢</span>
<span class=tag><a href=/tags/llm/>Llm</a>
</span><span class=separator>â€¢</span>
<span class=tag><a href=/tags/ai/>Ai</a>
</span><span class=separator>â€¢</span>
<span class=tag><a href=/tags/craft/>Craft</a>
</span><span class=separator>â€¢</span>
<span class=tag><a href=/tags/institutions/>Institutions</a>
</span><span class=separator>â€¢</span>
<span class=tag><a href=/tags/programming-as-theory-building/>Programming-as-Theory-Building</a></span></div></div></header><div class=post-content><p>In my <a href=/posts/programming-as-theory-building-naur/>previous post on Peter Naur&rsquo;s &ldquo;Programming as Theory Building&rdquo;</a>, I argued that a program is not its source codeâ€”it&rsquo;s the shared mental model held by the people who built it. When those people leave (or never understood it in the first place), the theory dies, and you&rsquo;re left with a codebase that works but nobody truly comprehends.</p><p>I&rsquo;ve been thinking about this more, and I&rsquo;ve come to believe the problem goes deeper than individual developers losing their edge. Yes, people are losing the ability to build theories. But the <em>institutions</em> where theory-building happens are being degraded too. Our teams, our companies, our profession. The whole ecosystem.</p><h2 id=software-teams-are-institutions>Software Teams Are Institutions
<a class=heading-link href=#software-teams-are-institutions><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>I recently read a draft paper by two Boston University law professors, Woodrow Hartzog and Jessica Silbey, called &ldquo;How AI Destroys Institutions.&rdquo; Their argument stopped me cold: AI systems aren&rsquo;t tools that <em>can</em> be misused. Their core design is incompatible with how institutions function.</p><p>Now, when they say &ldquo;institutions,&rdquo; they&rsquo;re talking about universities, the legal system, journalism, democracy. Big stuff. But as I read, I kept seeing my own world reflected back at me. Because software development teams <em>are</em> institutions, even if we don&rsquo;t usually think of them that way.</p><p>Consider what makes an institution work:</p><ul><li><strong>Hierarchies of expertise</strong>: Junior developers learn from seniors, who learned from principals, who learned from architects. Knowledge flows through these relationships.</li><li><strong>Shared purpose and rules</strong>: Coding standards, architectural decisions, domain models. The &ldquo;rules of the game&rdquo; that let a group of individuals function as a coherent team.</li><li><strong>Decision-making with accountability</strong>: Code reviews, design discussions, ADRs. Points where someone can say &ldquo;wait, that doesn&rsquo;t fit our model&rdquo; and actually be heard.</li><li><strong>Human relationships and solidarity</strong>: The trust that makes you ask a teammate for help instead of flailing alone. The camaraderie that makes you <em>want</em> the team to succeed.</li></ul><p>These are the machinery through which <em>theory gets built and transmitted</em>. Naur&rsquo;s insight was about individual understanding, but that understanding doesn&rsquo;t exist in a vacuum. It lives in the institution. In the conversations, the reviews, the mentoring, the shared struggle of building something together.</p><h2 id=the-three-ways-ai-degrades-institutions>The Three Ways AI Degrades Institutions
<a class=heading-link href=#the-three-ways-ai-degrades-institutions><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Hartzog and Silbey identify three &ldquo;destructive affordances&rdquo; of AI. Not things AI <em>might</em> do if misused, but things AI <em>does by design</em> when deployed the way its creators intend:</p><h3 id=1-ai-undermines-expertise>1. AI Undermines Expertise
<a class=heading-link href=#1-ai-undermines-expertise><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>This one connects directly to what I wrote before about &ldquo;reflexive AI usage&rdquo; robbing us of growth opportunities. But the institutional angle makes it worse.</p><p>When juniors accept AI-generated code they don&rsquo;t understand, they&rsquo;re not building theory. Fine, we knew that. But they&rsquo;re <em>also</em> not asking seniors for help, not struggling through code review, not having those hallway conversations where knowledge actually transfers. The institution&rsquo;s pipeline for developing expertiseâ€”which took decades to buildâ€”gets bypassed entirely.</p><p>And here&rsquo;s what gets me: AI can only look backwards. It&rsquo;s trained on what already exists. The institution&rsquo;s ability to <em>evolve</em> depends on humans doing the hard intellectual work of figuring out what doesn&rsquo;t exist yet. New patterns, new approaches, new understanding in response to changing circumstances. When that atrophies, the institution ossifies.</p><p>As the paper puts it: when AI is &ldquo;right,&rdquo; people become less skilled. When AI is &ldquo;wrong,&rdquo; you need skilled people to catch and fix the errors. Either way, the institution suffers.</p><p>A recent MIT Media Lab study puts numbers to this. Researchers had students write essays, with one group using ChatGPT and others using traditional methods. The result? 83% of the ChatGPT group couldn&rsquo;t quote anything they&rsquo;d written. They didn&rsquo;t remember. And they didn&rsquo;t feel like the work was theirs.</p><p>That&rsquo;s not just &ldquo;they didn&rsquo;t learn as much.&rdquo; That&rsquo;s <em>they didn&rsquo;t build any theory at all</em>. The understanding never formed. And if it never formed, it can never be transferred to the next generation of the institution.</p><h3 id=2-ai-short-circuits-decision-making>2. AI Short-Circuits Decision-Making
<a class=heading-link href=#2-ai-short-circuits-decision-making><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>Institutions need friction. Not bureaucratic friction for its own sake, but the productive kindâ€”moments where someone can push back, ask questions, challenge assumptions.</p><p>Think about a good code review. It&rsquo;s not just checking for bugs. It&rsquo;s a point of <em>contestation</em> where the team&rsquo;s shared understanding gets tested and refined. &ldquo;Why did you do it this way?&rdquo; &ldquo;Does this fit our domain model?&rdquo; &ldquo;Have you considered how this interacts with X?&rdquo; These questions are how theory gets sharpened and transmitted.</p><p>AI-generated code arrives without any of this context. There&rsquo;s no <code>git blame</code> pointing to a human you can ask. No PR discussion explaining the trade-offs. The code exists in what I called a &ldquo;theoretical vacuum,&rdquo; and when it enters your codebase, it imports architectural decisions that nobody on your team actually made.</p><p>The institution&rsquo;s decision-making process gets flattened. Rules become invisible. And when rules are invisible, they can&rsquo;t be questioned or iterated on. That&rsquo;s how institutions become rigid and eventually irrelevant.</p><h3 id=3-ai-isolates-humans>3. AI Isolates Humans
<a class=heading-link href=#3-ai-isolates-humans><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h3><p>This is the one that surprised me most, but I think it might be the most damaging in the long run.</p><p>Institutions run on human connection. The trust that makes someone ask for help instead of hiding their confusion. The solidarity that makes a team want to build something good together, not just ship features. The friction of working with people who think differently than youâ€”which is uncomfortable but essential for growth.</p><p>AI offers a sycophantic alternative. It never pushes back. It never says &ldquo;I don&rsquo;t understand what you&rsquo;re trying to do.&rdquo; It never asks the uncomfortable questions that force you to actually think through your approach. It tells you what you want to hear, generates what you asked for, and moves on.</p><p>Every minute a developer spends with an AI assistant is a minute not spent pairing with a colleague, not asking a question in Slack, not having the awkward conversation that might have revealed a fundamental misunderstanding. The paper calls this &ldquo;displacing opportunities for human connection,&rdquo; and I think that&rsquo;s exactly right.</p><p>Hartzog and Silbey cite a study showing that co-workers who receive &ldquo;workslop&rdquo; (AI outputs that make more work or make no sense) start seeing their colleagues differently. Less creative. Less capable. Less reliable. Less trustworthy. That&rsquo;s institutional trust eroding in real-time.</p><p>There&rsquo;s a darker psychological dimension here too. <a href="https://www.youtube.com/watch?v=zH2dFXDMwe4" class=external-link target=_blank rel=noopener>Mike Monteiro recently pointed out</a> that the AI industry&rsquo;s success depends on convincing people they&rsquo;re inadequate. Every time you open Google Docs and see those &ldquo;Help me write&rdquo; buttons, the message is clear: <em>you probably can&rsquo;t do this yourself</em>. We are not being built up by helpful tools. We&rsquo;re being torn down by tools that insist we can&rsquo;t function without them.</p><h2 id=the-theory-lives-in-the-institution>The Theory Lives in the Institution
<a class=heading-link href=#the-theory-lives-in-the-institution><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Here&rsquo;s where Naur&rsquo;s insight combines with the institutional perspective in a way that&rsquo;s hard to shake.</p><p>Remember: the program is not the code, it&rsquo;s the theory. But where does the theory actually live? Not just in individual heads, but in the <em>relationships between those heads</em>. In the shared understanding built through years of working together. In the institutional memory of why we do things this way and not that way.</p><p>When AI undermines expertise, short-circuits decision-making, and isolates humans, the damage goes beyond individual developers getting worse. It&rsquo;s destroying the place where theory actually lives.</p><p>A junior who never struggles through a difficult problem doesn&rsquo;t just fail to learn. They fail to develop the relationships with seniors that would have formed during that struggle. An AI-generated PR that nobody truly reviews doesn&rsquo;t just introduce risky code. It skips the conversation that would have refined everyone&rsquo;s understanding of the domain. A developer who &ldquo;pairs&rdquo; with an AI instead of a colleague doesn&rsquo;t just miss out on connection. They miss the creative friction that produces genuinely new ideas.</p><p>The theory, in other words, doesn&rsquo;t just die with individuals. It dies when the institution that builds and sustains it crumbles.</p><h2 id=where-ai-actually-helps-with-clear-constraints>Where AI Actually Helps (With Clear Constraints)
<a class=heading-link href=#where-ai-actually-helps-with-clear-constraints><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>I&rsquo;m not saying never use AI. <a href=/posts/coding-as-craft-going-back-to-the-old-gym/>As I&rsquo;ve written before</a>, AI excels at automating the boring partsâ€”and there&rsquo;s nothing wrong with that.</p><p>But the key word is <em>constraints</em>. The successful uses I&rsquo;ve seen have something in common:</p><p><strong>The human sets the theory, and the AI executes within it.</strong></p><p>For example: &ldquo;I&rsquo;ve written tests for these three controllers following this pattern. Here&rsquo;s how they behave, here are the edge cases I&rsquo;m covering, here&rsquo;s why. Now write tests for these two other controllers using the same approach. Ask me whenever something doesn&rsquo;t translate 1:1.&rdquo;</p><p>Notice what&rsquo;s happening here. The human has done the theory-building work: understanding the domain, making architectural decisions, establishing patterns. The AI is doing rote execution <em>within</em> that established framework. And crucially, there&rsquo;s a checkpoint: &ldquo;ask me whenever something doesn&rsquo;t translate 1:1.&rdquo; The human stays in the loop, ready to exercise judgment when the pattern breaks down.</p><p>This is AI as a tool that serves your expertise. It&rsquo;s not AI as a replacement for the hard intellectual work.</p><p>The difference matters. Boilerplate generation, documentation summarization, test scaffolding within an established pattern. These don&rsquo;t require theory-building. They don&rsquo;t involve the architectural decisions and domain understanding that give a codebase its coherence. Using AI for these is like using a calculator for arithmetic: it frees up mental energy for the work that actually matters.</p><p>But &ldquo;write me a feature&rdquo; or &ldquo;fix this bug&rdquo; or &ldquo;refactor this module&rdquo;â€”these <em>do</em> involve theory. They require understanding why things are the way they are and how they should evolve. Offloading this to AI doesn&rsquo;t just skip the struggle. It skips the institutional processes that would have refined that theory and transmitted it to others.</p><h2 id=what-were-actually-fighting-for>What We&rsquo;re Actually Fighting For
<a class=heading-link href=#what-were-actually-fighting-for><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>The AI boosters will tell you this is all about efficiency. &ldquo;AI systems are just tools,&rdquo; they say. &ldquo;They help us do what we were going to do anyway, only faster.&rdquo;</p><p>But that framing misses what institutions actually <em>are</em>. They&rsquo;re not just machines for producing output. They&rsquo;re where expertise gets built, where decisions get made well, where people actually connect with each other. Speed those things up too much and they stop working.</p><p>What we&rsquo;re fighting for isn&rsquo;t just our individual craft, though that matters too. It&rsquo;s the institutions that make software development a <em>profession</em> rather than just a job. The mentorship that turns juniors into seniors. The processes that keep codebases coherent over time. The relationships that make a team actually <em>work</em>.</p><p>But maybe there&rsquo;s something even more basic at stake. Human beings are <em>made</em> to create. A child draws an orange on the first day of art class without hesitation, without permission, without worrying whether they&rsquo;re &ldquo;good enough.&rdquo; That impulse to make marks on the world, to build things, to leave evidence that we were here. It&rsquo;s in our bones. And when we&rsquo;re convinced we can&rsquo;t create, something essential gets stolen from us.</p><p>This is the other half of what Monteiro was getting at. Once you convince people they can&rsquo;t express themselves, it&rsquo;s that much easier to convince them they can&rsquo;t govern themselves. The path from &ldquo;let AI write your code&rdquo; to &ldquo;let AI make your decisions&rdquo; to &ldquo;you&rsquo;re not competent to have a say&rdquo; is shorter than we think.</p><p>These institutions took decades to build. They&rsquo;re far more fragile than we realized.</p><h2 id=the-center-cannot-hold>The Center Cannot Hold
<a class=heading-link href=#the-center-cannot-hold><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Hartzog and Silbey end their paper with a warning: &ldquo;Because AI is anathema to the well-being of our critical institutions, absent rules mitigating AI&rsquo;s cancerous spread, the only roads left lead to social dissolution.&rdquo;</p><p>That&rsquo;s strong language for a legal academic paper. But I think they&rsquo;re right. And I think it applies to our institutions too.</p><p>Software development teams that fully embrace &ldquo;reflexive AI usage&rdquo; will find their expertise pipelines broken, their decision-making processes hollowed out, their human connections atrophied. The theory will die. The code will remain, but nobody will understand it. And then the institutional knowledge will be gone, and no amount of AI will bring it back.</p><p>In my previous post, I wrote: &ldquo;When the dust of this Null-Stack Vibe Bonanza has settled, they&rsquo;ll once again be looking for senior developers.&rdquo;</p><p>I still believe that. But I&rsquo;m less certain there will be any institutions left to produce them.</p></div><footer></footer></article></section></div><style>form{display:flex;justify-content:center}</style><form action="https://api.follow.it/subscription-form/SDRVMUk2VmsySENBNk94RDNKNDFnS3NmWlQ5a3gxejNIeUlJWHl3QjdqNnRHdENkaXp5aXZhZlFvcGtzcEZ3K0o5TFVRdSt2WWM5RWRsWmZwWVhNUS9PZjJqMWZ3aHBwZUhjT1ZpWXBGRkdZOWtIcGhYQkJkSkE4QTQ1eHl5YkF8RTZHTExQOWFrN1pFY1F0RzZ5c3pVN2I1QTI1YXNtMjZiYllLU25zQkJ3bz0=/8" method=post onsubmit=onSubscribe()><input type=email name=email required placeholder=Email spellcheck=false style="padding:1rem;border:none;border-radius:1rem 0 0 1rem;outline:none">
<button type=submit style="border:none;border-radius:0 1rem 1rem 0;outline:none;background:rgba(127,127,127,5%);cursor:pointer">
Subscribe</button></form><div id=elm-widget></div><script src=/widget.js></script><script>Elm.Main.init({node:document.getElementById("elm-widget"),flags:window.location.pathname})</script><script type=text/javascript src="https://platform-api.sharethis.com/js/sharethis.js#property=6834b86198608700128c9ffa&product=sticky-share-buttons" async></script><footer class=footer><section class=container>Â© 2021 - 2026 Christian Ekrem
<script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-emoji=ðŸº data-id=cekrem data-description="Support me on Buy me a coffee!" data-message data-color=#ddd data-position=Left data-x_margin=18 data-y_margin=18></script></section><script src=https://formspree.io/js/formbutton-v1.min.js defer></script></footer><script src=https://sdk.feedback.one/v0/core.min.js data-project-id=019589e0-c6fb-7b80-b6ae-dffbfbb11f72 defer></script><script>!function(e,t){var n,s,o,i;t.__SV||window.posthog&&window.posthog.__loaded||(window.posthog=t,t._i=[],t.init=function(a,r,c){function d(e,t){var n=t.split(".");2==n.length&&(e=e[n[0]],t=n[1]),e[t]=function(){e.push([t].concat(Array.prototype.slice.call(arguments,0)))}}(n=e.createElement("script")).type="text/javascript",n.crossOrigin="anonymous",n.async=!0,n.src=r.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(i=e.getElementsByTagName("script")[0]).parentNode.insertBefore(n,i);var l=t;for(0[0]!==c?l=t[c]=[]:c="posthog",l.people=l.people||[],l.toString=function(e){var t="posthog";return"posthog"!==c&&(t+="."+c),e||(t+=" (stub)"),t},l.people.toString=function(){return l.toString(1)+".people (stub)"},o="init Rr Mr fi Or Ar ci Tr Cr capture Mi calculateEventProperties Lr register register_once register_for_session unregister unregister_for_session Hr getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSurveysLoaded onSessionId getSurveys getActiveMatchingSurveys renderSurvey displaySurvey canRenderSurvey canRenderSurveyAsync identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty Ur jr createPersonProfile zr kr Br opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing get_explicit_consent_status is_capturing clear_opt_in_out_capturing Dr debug M Nr getPageViewId captureTraceFeedback captureTraceMetric $r".split(" "),s=0;s<o.length;s++)d(l,o[s]);t._i.push([a,r,c])},t.__SV=1)}(document,window.posthog||[]),posthog.init("phc_AHy7NSMntJJLr0hUSCwdUS1eRq6SaEqacK1Mzzf36ED",{api_host:"https://eu.i.posthog.com",defaults:"2025-05-24",person_profiles:"identified_only"});function onSubscribe(){posthog.capture("new subscriber")}</script></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script><script data-goatcounter=https://cekrem.goatcounter.com/count async src=//gc.zgo.at/count.js></script></body></html>